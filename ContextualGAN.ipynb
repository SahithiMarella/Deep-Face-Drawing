{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "# from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "# from tensorflow_addons.layers import InstanceNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization as InstanceNormalization\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, BatchNormalization, Activation, ZeroPadding2D\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "# from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.layers import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import natsort\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filename(path):\n",
    "    dirFiles = os.listdir(path)\n",
    "    for i, file in enumerate(dirFiles):\n",
    "        dirFiles[i] = path + file\n",
    "    return natsort.natsorted(dirFiles ,reverse=False)\n",
    "\n",
    "# load all images in a directory into memory\n",
    "def load_images(list_path, size=(256, 256)):\n",
    "    img_list = list()\n",
    "    # enumerate filenames in directory, assume all are images\n",
    "    for filename in list_path:\n",
    "        # load and resize the image\n",
    "        pixels = load_img(filename, target_size=size)\n",
    "        # convert to numpy array\n",
    "        pixels = img_to_array(pixels)\n",
    "        pixels = (pixels - 127.5) / 127.5\n",
    "        img_list.append(pixels)\n",
    "    return np.asarray(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "\n",
    "    # choose random instances\n",
    "    ix = np.random.randint(0, trainA.shape[0], n_samples)\n",
    "    \n",
    "    # retrieve selected images\n",
    "    X1, X2 = trainA[ix], trainB[ix]\n",
    "    \n",
    "    # generate 'real' class labels (1)\n",
    "    y = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    \n",
    "    return [X1, X2], y\n",
    "\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(samples)\n",
    "    \n",
    "    # create 'fake' class labels (0)\n",
    "    y = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, d_model, dataset, target_dir='', n_samples=3):\n",
    "    if target_dir and not os.path.exists(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "    # select a sample of input images\n",
    "    [X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n",
    "    # generate a batch of fake samples\n",
    "    X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "    # scale all pixels from [-1,1] to [0,1]\n",
    "    X_realA = (X_realA + 1) / 2.0\n",
    "    X_realB = (X_realB + 1) / 2.0\n",
    "    X_fakeB = (X_fakeB + 1) / 2.0\n",
    "    # plot real source images\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realA[i])\n",
    "    # plot generated target image\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + n_samples + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_fakeB[i])\n",
    "    # plot real target image\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realB[i])\n",
    "    # save plot to file\n",
    "    filename1 = 'plot_%06d.png' % (step+1)\n",
    "    plt.savefig(target_dir + filename1)\n",
    "    plt.close()\n",
    "    # save the generator model\n",
    "    g_model.save(target_dir + 'g_model.h5')\n",
    "    \n",
    "    # save the discriminator model\n",
    "    d_model.save(target_dir + 'd_model.h5')\n",
    "    \n",
    "    print('>Saved: %s and %s' % (filename1, 'g_model & d_model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(img_shape):\n",
    "    def conv2d(layer_in, n_filter, norm=True):\n",
    "        d = Conv2D(n_filter, kernel_size=4, strides=2, padding='same')(layer_in)\n",
    "        d = LeakyReLU(0.2)(d)\n",
    "        if norm:\n",
    "            d = InstanceNormalization()(d)\n",
    "        return d\n",
    "    \n",
    "    def deconv2d(layer_in, skip_in, n_filter, dropout=0.5):\n",
    "        d = UpSampling2D(size=2)(layer_in)\n",
    "        d = Conv2D(n_filter, kernel_size=4, strides=1, padding='same', activation='relu')(d)\n",
    "        if dropout:\n",
    "            d = Dropout(dropout)(d)\n",
    "        d = InstanceNormalization()(d)\n",
    "        d = Concatenate()([d, skip_in])\n",
    "        return d\n",
    "    \n",
    "    # Input Layer\n",
    "    in_img = Input(shape=img_shape)\n",
    "    \n",
    "    # Downsampling\n",
    "    d1 = conv2d(in_img, 64, norm=False)\n",
    "    d2 = conv2d(d1, 128)\n",
    "    d3 = conv2d(d2, 256)\n",
    "    d4 = conv2d(d3, 512)\n",
    "    d5 = conv2d(d4, 512)\n",
    "    d6 = conv2d(d5, 512)\n",
    "    d7 = conv2d(d6, 512)\n",
    "    \n",
    "    # Upsampling\n",
    "    u1 = deconv2d(d7, d6, 512)\n",
    "    u2 = deconv2d(u1, d5, 512)\n",
    "    u3 = deconv2d(u2, d4, 512)\n",
    "    u4 = deconv2d(u3, d3, 256, dropout=0)\n",
    "    u5 = deconv2d(u4, d2, 128, dropout=0)\n",
    "    u6 = deconv2d(u5, d1, 64, dropout=0)\n",
    "    u7 = UpSampling2D(size=2)(u6)\n",
    "    \n",
    "    out_img = Conv2D(3, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "    \n",
    "    return Model(in_img, out_img, name='generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(img_shape):\n",
    "    def d_layer(layer_in, n_filter, norm=True):\n",
    "        d = Conv2D(n_filter, kernel_size=4, strides=2, padding='same')(layer_in)\n",
    "        d = LeakyReLU(0.2)(d)\n",
    "        if norm:\n",
    "            d = InstanceNormalization()(d)\n",
    "        return d\n",
    "    \n",
    "    in_src_img = Input(shape=img_shape)\n",
    "    in_target_img = Input(shape=img_shape)\n",
    "    \n",
    "    merged = Concatenate()([in_src_img, in_target_img])\n",
    "    \n",
    "    d1 = d_layer(merged, 64, norm=False)\n",
    "    d2 = d_layer(d1, 128)\n",
    "    d3 = d_layer(d1, 256)\n",
    "    d4 = d_layer(d1, 512)\n",
    "\n",
    "    out = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "    \n",
    "    return Model([in_src_img, in_target_img], out, name='discriminator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAN(g_model, d_model, img_shape):\n",
    "    d_model.trainable = False\n",
    "    in_img = Input(shape=img_shape)\n",
    "    gen_out = g_model(in_img)\n",
    "    dis_out = d_model([in_img, gen_out])\n",
    "    model = Model(in_img, [dis_out, gen_out], name='GAN')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(d_model, g_model, gan_model, data, target_dir, n_epochs=150, n_batch=32):\n",
    "    # determine the output square shape of the discriminator\n",
    "    n_patch = d_model.output_shape[1]\n",
    "    \n",
    "    blue_photo = data[0]\n",
    "    blue_sketch = data[1]\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        print(' ========== Epoch', i+1, '========== ')\n",
    "        \n",
    "        blue_photo, blue_sketch = shuffle(blue_photo, blue_sketch)\n",
    "\n",
    "        for j in range(int(len(blue_photo)/n_batch)):\n",
    "            \n",
    "            start = int(j*n_batch)\n",
    "            end = int(min(len(blue_photo), (j*n_batch)+n_batch))\n",
    "            \n",
    "            dataset = [load_images(blue_photo[start:end]), load_images(blue_sketch[start:end])]\n",
    "\n",
    "            # select a batch of real samples\n",
    "            [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
    "            \n",
    "            # generate a batch of fake samples\n",
    "            X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "            \n",
    "            # update discriminator for real samples\n",
    "            d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "            \n",
    "            # update discriminator for generated samples\n",
    "            d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss1, d_loss2)\n",
    "            \n",
    "            # update the generator\n",
    "            g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "            \n",
    "            # summarize performance\n",
    "            print('Batch : %d, D Loss : %.3f | G Loss : %.3f' % (j+1, d_loss, g_loss))\n",
    "        \n",
    "        # summarize model performance\n",
    "#         if (i+1) % 10 == 0:\n",
    "        summarize_performance(i, g_model, d_model, dataset, target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.losses import mean_absolute_error\n",
    "import tensorflow.keras.backend as K  \n",
    "\n",
    "def pixel_loss(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_true - y_pred))\n",
    "\n",
    "def contextual_loss (y_true, y_pred):\n",
    "    a = tf.image.rgb_to_grayscale(tf.slice(\n",
    "                                y_pred, \n",
    "                                [0,0,0,0], \n",
    "                                [16, 256, 256, 3]))\n",
    "    \n",
    "    b = tf.image.rgb_to_grayscale(tf.slice(\n",
    "                                y_true, \n",
    "                                [0,0,0,0], \n",
    "                                [16, 256, 256, 3]))\n",
    "    \n",
    "    y_pred = tf.divide(tf.add(tf.reshape(a, [tf.shape(a)[0], -1]), 1), 2)\n",
    "    y_true = tf.divide(tf.add(tf.reshape(b, [tf.shape(b)[0], -1]), 1), 2)\n",
    "    \n",
    "#     tf.assert_rank(y_true,2)\n",
    "#     tf.assert_rank(y_pred,2)\n",
    "    \n",
    "    p_shape = tf.shape(y_true)\n",
    "    q_shape = tf.shape(y_pred)\n",
    "#     tf.assert_equal(p_shape, q_shape)\n",
    "    \n",
    "    # normalize sum to 1\n",
    "    p_ = tf.divide(y_true, tf.tile(tf.expand_dims(tf.reduce_sum(y_true, axis=1), 1), [1,p_shape[1]]))\n",
    "    q_ = tf.divide(y_pred, tf.tile(tf.expand_dims(tf.reduce_sum(y_pred, axis=1), 1), [1,p_shape[1]]))\n",
    "    \n",
    "    return tf.reduce_sum(tf.multiply(p_, tf.math.log(tf.divide(p_, q_))), axis=1)\n",
    "\n",
    "def total_loss (y_true, y_pred):\n",
    "\n",
    "    px_loss = pixel_loss(y_true, y_pred)\n",
    "\n",
    "    ctx_loss = contextual_loss(y_true, y_pred)\n",
    "    \n",
    "    return (0.2 * px_loss) + (0.8 * ctx_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset path\n",
    "b_photo_path = 'Dataset/Augmented photo/'\n",
    "b_sketch_path = 'Dataset/Augmented sketch/'\n",
    "\n",
    "blue_photo = load_filename(b_photo_path)\n",
    "blue_sketch = load_filename(b_sketch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23eb7b56720>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cv2.cvtColor(cv2.imread(blue_photo[1500]).astype('uint8'), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23eb99b49e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cv2.cvtColor(cv2.imread(blue_sketch[1500]).astype('uint8'), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_shape = (256, 256, 3)\n",
    "\n",
    "d_model = discriminator(img_shape)\n",
    "\n",
    "g_model = generator(img_shape)\n",
    "\n",
    "gan_model = GAN(g_model, d_model, img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"GAN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"GAN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ generator           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">41,843,331</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ discriminator       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">541,249</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ generator           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │ \u001b[38;5;34m41,843,331\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ discriminator       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m) │    \u001b[38;5;34m541,249\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,384,580</span> (161.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,384,580\u001b[0m (161.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,834,499</span> (159.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,834,499\u001b[0m (159.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">550,081</span> (2.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m550,081\u001b[0m (2.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam  # Ensure Adam is imported properly\n",
    "d_model.trainable = True\n",
    "g_model.trainable = True\n",
    "gan_model.trainable = True\n",
    "\n",
    "opt = Adam(learning_rate=2e-4, beta_1=0.5)\n",
    "\n",
    "\n",
    "d_model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "gan_model.compile(loss=['binary_crossentropy', total_loss], optimizer=opt, loss_weights=[1,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure models are trainable before compiling\n",
    "# d_model.trainable = True\n",
    "# g_model.trainable = True\n",
    "# gan_model.trainable = True\n",
    "\n",
    "# # Compile models again after setting them as trainable\n",
    "# d_model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "# gan_model.compile(loss=['binary_crossentropy', total_loss], optimizer=opt, loss_weights=[1,100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== Epoch 1 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahul\\sath\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch : 1, D Loss : 3.796 | G Loss : 100.816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 2, D Loss : 3.705 | G Loss : 86.010\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 3, D Loss : 3.661 | G Loss : 76.020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 4, D Loss : 3.636 | G Loss : 69.829\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 5, D Loss : 3.618 | G Loss : 65.552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 6, D Loss : 3.612 | G Loss : 62.636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 7, D Loss : 3.614 | G Loss : 60.279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 8, D Loss : 3.616 | G Loss : 58.312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 9, D Loss : 3.606 | G Loss : 56.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 10, D Loss : 3.597 | G Loss : 54.791\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 11, D Loss : 3.599 | G Loss : 53.306\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 12, D Loss : 3.593 | G Loss : 51.910\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 13, D Loss : 3.595 | G Loss : 50.793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 14, D Loss : 3.594 | G Loss : 49.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 15, D Loss : 3.584 | G Loss : 48.929\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 16, D Loss : 3.581 | G Loss : 48.119\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 17, D Loss : 3.578 | G Loss : 47.317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 18, D Loss : 3.577 | G Loss : 46.538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 19, D Loss : 3.578 | G Loss : 45.861\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 20, D Loss : 3.575 | G Loss : 45.209\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 21, D Loss : 3.574 | G Loss : 44.593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 22, D Loss : 3.575 | G Loss : 43.928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 23, D Loss : 3.574 | G Loss : 43.430\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 24, D Loss : 3.573 | G Loss : 42.950\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 25, D Loss : 3.574 | G Loss : 42.441\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 26, D Loss : 3.572 | G Loss : 42.003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 27, D Loss : 3.573 | G Loss : 41.607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 28, D Loss : 3.575 | G Loss : 41.311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 29, D Loss : 3.574 | G Loss : 41.046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 30, D Loss : 3.575 | G Loss : 40.796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 31, D Loss : 3.572 | G Loss : 40.497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 32, D Loss : 3.572 | G Loss : 40.194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.571 | G Loss : 39.902\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.570 | G Loss : 39.559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.569 | G Loss : 39.235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.567 | G Loss : 38.944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.567 | G Loss : 38.664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.566 | G Loss : 38.402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.567 | G Loss : 38.164\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.566 | G Loss : 37.952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.564 | G Loss : 37.733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.564 | G Loss : 37.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.565 | G Loss : 37.298\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.564 | G Loss : 37.161\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.567 | G Loss : 36.983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 46, D Loss : 3.567 | G Loss : 36.794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000001.png and g_model & d_model\n",
      " ========== Epoch 2 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.567 | G Loss : 36.602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.565 | G Loss : 36.423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.564 | G Loss : 36.272\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.564 | G Loss : 36.165\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.564 | G Loss : 36.090\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.564 | G Loss : 36.013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.566 | G Loss : 35.920\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.567 | G Loss : 35.811\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.567 | G Loss : 35.698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.569 | G Loss : 35.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.568 | G Loss : 35.503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.567 | G Loss : 35.390\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.567 | G Loss : 35.282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.567 | G Loss : 35.138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.566 | G Loss : 35.018\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.565 | G Loss : 34.885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.565 | G Loss : 34.758\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.565 | G Loss : 34.631\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.565 | G Loss : 34.500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.564 | G Loss : 34.411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.564 | G Loss : 34.310\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.563 | G Loss : 34.203\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.564 | G Loss : 34.107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.563 | G Loss : 34.042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.563 | G Loss : 33.946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.562 | G Loss : 33.848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.562 | G Loss : 33.728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.560 | G Loss : 33.633\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.561 | G Loss : 33.527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.560 | G Loss : 33.433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.561 | G Loss : 33.338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.560 | G Loss : 33.252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.561 | G Loss : 33.160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.560 | G Loss : 33.067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.560 | G Loss : 32.983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.560 | G Loss : 32.890\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.560 | G Loss : 32.795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.560 | G Loss : 32.710\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.560 | G Loss : 32.634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.560 | G Loss : 32.559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.560 | G Loss : 32.475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 42, D Loss : 3.560 | G Loss : 32.395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.560 | G Loss : 32.319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.559 | G Loss : 32.246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.559 | G Loss : 32.185\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.558 | G Loss : 32.110\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000002.png and g_model & d_model\n",
      " ========== Epoch 3 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 1, D Loss : 3.558 | G Loss : 32.044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.557 | G Loss : 31.974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.558 | G Loss : 31.939\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.559 | G Loss : 31.869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.559 | G Loss : 31.801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.559 | G Loss : 31.744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.559 | G Loss : 31.686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.560 | G Loss : 31.645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.560 | G Loss : 31.600\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.559 | G Loss : 31.543\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.559 | G Loss : 31.491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.559 | G Loss : 31.428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.558 | G Loss : 31.374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.557 | G Loss : 31.324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.557 | G Loss : 31.279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.557 | G Loss : 31.227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.556 | G Loss : 31.170\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.557 | G Loss : 31.136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.557 | G Loss : 31.076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.557 | G Loss : 31.019\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.557 | G Loss : 30.957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.558 | G Loss : 31.006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.558 | G Loss : 30.989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.559 | G Loss : 30.967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.558 | G Loss : 30.973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.557 | G Loss : 30.942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.556 | G Loss : 30.908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.556 | G Loss : 30.887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.556 | G Loss : 30.842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.556 | G Loss : 30.816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.556 | G Loss : 30.789\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.557 | G Loss : 30.748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.556 | G Loss : 30.703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.556 | G Loss : 30.657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.557 | G Loss : 30.618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.556 | G Loss : 30.575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.556 | G Loss : 30.533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.556 | G Loss : 30.487\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.556 | G Loss : 30.445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.557 | G Loss : 30.406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.557 | G Loss : 30.371\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.557 | G Loss : 30.338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.557 | G Loss : 30.307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.557 | G Loss : 30.284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.556 | G Loss : 30.242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.557 | G Loss : 30.217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000003.png and g_model & d_model\n",
      " ========== Epoch 4 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 1, D Loss : 3.557 | G Loss : 30.178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 2, D Loss : 3.556 | G Loss : 30.150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 3, D Loss : 3.556 | G Loss : 30.105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.556 | G Loss : 30.064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.556 | G Loss : 30.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.556 | G Loss : 29.986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.556 | G Loss : 29.986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 8, D Loss : 3.556 | G Loss : 29.970\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 29.953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.556 | G Loss : 29.933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.556 | G Loss : 29.905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 29.884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 29.856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 29.825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 29.793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 29.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 29.729\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 29.700\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 29.671\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 29.642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 29.609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 29.581\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 29.554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 29.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 29.491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 29.468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 29.435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 29.409\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 29.385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 29.351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 29.319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 29.292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 29.265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 29.240\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 29.214\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 29.192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 29.160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 29.127\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 29.099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 29.071\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 29.039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 29.012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 28.985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 28.958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 28.928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 28.907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000004.png and g_model & d_model\n",
      " ========== Epoch 5 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 28.886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 28.872\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 28.849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 28.830\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 28.810\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 28.785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 28.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.553 | G Loss : 28.736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 28.712\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 28.684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 28.656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 28.634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 28.611\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 28.590\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 28.561\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 28.541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 28.525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 28.513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 28.494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 28.469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 28.448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 28.424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 28.403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 28.379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 28.354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 28.327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 28.302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 28.280\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 28.258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 28.239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 28.219\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 28.197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 28.171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 28.157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 28.138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 28.119\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 28.098\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 28.078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 28.058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 28.035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 28.013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 27.992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 27.973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 27.949\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 27.935\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.556 | G Loss : 27.917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000005.png and g_model & d_model\n",
      " ========== Epoch 6 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 27.903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 27.884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 27.865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 4, D Loss : 3.556 | G Loss : 27.848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.556 | G Loss : 27.826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.556 | G Loss : 27.802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.556 | G Loss : 27.781\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.556 | G Loss : 27.758\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 27.737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 27.717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 27.696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 27.675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 27.655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 27.637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 27.618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 27.598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 27.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.556 | G Loss : 27.564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 27.547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 27.529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 27.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 27.494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 27.477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 27.460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.556 | G Loss : 27.442\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 27.423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 27.400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 27.379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 27.360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 27.374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 27.366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 27.355\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 27.343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 27.331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 27.324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 27.313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 27.299\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 27.284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 27.266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 27.251\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 27.236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 27.219\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 27.203\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 27.186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 27.171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 27.155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000006.png and g_model & d_model\n",
      " ========== Epoch 7 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 27.144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 27.127\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 27.108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 27.094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 27.078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 27.063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 27.048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 27.031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 27.016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 27.002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 26.987\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 26.975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 26.964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 26.946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 26.928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 26.917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 26.911\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 26.904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 26.893\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 26.880\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 26.869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 26.852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 26.836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 26.818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 26.807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 26.795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 26.785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 26.778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 26.764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 26.748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 26.737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 26.728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 26.713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 26.700\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 26.685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 26.670\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 26.654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 26.643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 26.628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 26.613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 26.598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 26.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 26.575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 26.561\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 26.547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 26.533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000007.png and g_model & d_model\n",
      " ========== Epoch 8 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 26.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 26.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 26.502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 26.494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 26.484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 26.474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 26.463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 26.450\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 26.438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 26.424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.553 | G Loss : 26.409\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 26.396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 26.394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 26.391\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 26.389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 26.382\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 26.376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 18, D Loss : 3.553 | G Loss : 26.364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.553 | G Loss : 26.353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.553 | G Loss : 26.343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 21, D Loss : 3.553 | G Loss : 26.329\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.553 | G Loss : 26.320\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 23, D Loss : 3.553 | G Loss : 26.308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.553 | G Loss : 26.295\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.553 | G Loss : 26.283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.552 | G Loss : 26.273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 27, D Loss : 3.553 | G Loss : 26.262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 28, D Loss : 3.552 | G Loss : 26.251\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 29, D Loss : 3.552 | G Loss : 26.242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.553 | G Loss : 26.234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 31, D Loss : 3.553 | G Loss : 26.226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 32, D Loss : 3.553 | G Loss : 26.214\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 33, D Loss : 3.553 | G Loss : 26.205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.553 | G Loss : 26.195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.553 | G Loss : 26.183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.553 | G Loss : 26.172\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.553 | G Loss : 26.162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.553 | G Loss : 26.154\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.553 | G Loss : 26.143\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.553 | G Loss : 26.131\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.553 | G Loss : 26.120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.553 | G Loss : 26.112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.553 | G Loss : 26.100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.553 | G Loss : 26.088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.553 | G Loss : 26.080\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.553 | G Loss : 26.073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000008.png and g_model & d_model\n",
      " ========== Epoch 9 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.553 | G Loss : 26.064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.553 | G Loss : 26.054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 3, D Loss : 3.553 | G Loss : 26.044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.553 | G Loss : 26.032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.553 | G Loss : 26.019\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.553 | G Loss : 26.008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.553 | G Loss : 25.999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.553 | G Loss : 25.990\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 9, D Loss : 3.553 | G Loss : 25.981\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 10, D Loss : 3.553 | G Loss : 25.970\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 11, D Loss : 3.553 | G Loss : 25.961\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 12, D Loss : 3.553 | G Loss : 25.951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 13, D Loss : 3.553 | G Loss : 25.940\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.553 | G Loss : 25.934\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 15, D Loss : 3.553 | G Loss : 25.926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 16, D Loss : 3.553 | G Loss : 25.918\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 25.909\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.553 | G Loss : 25.904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 25.897\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 25.889\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "Batch : 21, D Loss : 3.553 | G Loss : 25.879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 25.873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 25.867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 25.858\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.553 | G Loss : 25.851\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.553 | G Loss : 25.842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 25.837\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.553 | G Loss : 25.829\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.553 | G Loss : 25.818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.553 | G Loss : 25.809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.553 | G Loss : 25.800\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 25.789\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 25.785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 25.778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 25.770\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 25.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 25.752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 25.744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 25.735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 25.724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 25.716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 25.709\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 25.698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 25.689\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 25.681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 25.672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000009.png and g_model & d_model\n",
      " ========== Epoch 10 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 25.664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 25.655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 25.646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 25.636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 25.626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 25.620\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 25.615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.553 | G Loss : 25.605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 25.599\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 25.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.553 | G Loss : 25.581\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.553 | G Loss : 25.574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.553 | G Loss : 25.564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.553 | G Loss : 25.554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 25.547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 25.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 25.531\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.553 | G Loss : 25.521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 19, D Loss : 3.553 | G Loss : 25.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.553 | G Loss : 25.504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.553 | G Loss : 25.498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.553 | G Loss : 25.489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.553 | G Loss : 25.480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.553 | G Loss : 25.475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 25.466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.553 | G Loss : 25.460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 25.455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 28, D Loss : 3.553 | G Loss : 25.446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 25.438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 30, D Loss : 3.553 | G Loss : 25.429\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 31, D Loss : 3.553 | G Loss : 25.421\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 32, D Loss : 3.553 | G Loss : 25.412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 33, D Loss : 3.553 | G Loss : 25.403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.553 | G Loss : 25.394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.553 | G Loss : 25.385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.553 | G Loss : 25.379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.553 | G Loss : 25.373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 38, D Loss : 3.553 | G Loss : 25.365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.553 | G Loss : 25.357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.553 | G Loss : 25.349\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.553 | G Loss : 25.341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.553 | G Loss : 25.330\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.553 | G Loss : 25.321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.553 | G Loss : 25.314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.553 | G Loss : 25.305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.553 | G Loss : 25.298\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000010.png and g_model & d_model\n",
      " ========== Epoch 11 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.553 | G Loss : 25.291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.553 | G Loss : 25.287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.553 | G Loss : 25.282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.553 | G Loss : 25.274\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.553 | G Loss : 25.266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.553 | G Loss : 25.259\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.553 | G Loss : 25.252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.553 | G Loss : 25.245\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.553 | G Loss : 25.239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 10, D Loss : 3.553 | G Loss : 25.232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.553 | G Loss : 25.226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 12, D Loss : 3.553 | G Loss : 25.221\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 13, D Loss : 3.553 | G Loss : 25.214\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 14, D Loss : 3.553 | G Loss : 25.209\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 15, D Loss : 3.553 | G Loss : 25.202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.553 | G Loss : 25.195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.553 | G Loss : 25.188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 18, D Loss : 3.553 | G Loss : 25.180\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.553 | G Loss : 25.173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.553 | G Loss : 25.164\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.553 | G Loss : 25.155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.553 | G Loss : 25.151\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.553 | G Loss : 25.143\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.553 | G Loss : 25.135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.553 | G Loss : 25.127\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.553 | G Loss : 25.121\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.553 | G Loss : 25.114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.553 | G Loss : 25.107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.553 | G Loss : 25.102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.553 | G Loss : 25.096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.553 | G Loss : 25.091\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.553 | G Loss : 25.088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.553 | G Loss : 25.081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.553 | G Loss : 25.075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.553 | G Loss : 25.067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.553 | G Loss : 25.062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.553 | G Loss : 25.053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.553 | G Loss : 25.047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.553 | G Loss : 25.042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.553 | G Loss : 25.034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.553 | G Loss : 25.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.553 | G Loss : 25.018\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 43, D Loss : 3.553 | G Loss : 25.012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.553 | G Loss : 25.005\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.553 | G Loss : 24.999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.553 | G Loss : 24.991\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000011.png and g_model & d_model\n",
      " ========== Epoch 12 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.553 | G Loss : 24.985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.553 | G Loss : 24.978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 3, D Loss : 3.553 | G Loss : 24.968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.553 | G Loss : 24.960\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.553 | G Loss : 24.952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.553 | G Loss : 24.944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.553 | G Loss : 24.937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.553 | G Loss : 24.929\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.553 | G Loss : 24.924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.553 | G Loss : 24.918\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.553 | G Loss : 24.912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.553 | G Loss : 24.909\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.553 | G Loss : 24.903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.553 | G Loss : 24.895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.553 | G Loss : 24.888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.553 | G Loss : 24.881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.553 | G Loss : 24.874\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.553 | G Loss : 24.866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.553 | G Loss : 24.858\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.553 | G Loss : 24.851\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 24.843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.553 | G Loss : 24.836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.553 | G Loss : 24.828\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.553 | G Loss : 24.820\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.553 | G Loss : 24.812\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.553 | G Loss : 24.806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.553 | G Loss : 24.804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.553 | G Loss : 24.796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.553 | G Loss : 24.788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.553 | G Loss : 24.782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.553 | G Loss : 24.776\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.553 | G Loss : 24.768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.553 | G Loss : 24.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.553 | G Loss : 24.753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.553 | G Loss : 24.746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.553 | G Loss : 24.741\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.553 | G Loss : 24.735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.553 | G Loss : 24.730\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.553 | G Loss : 24.723\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.553 | G Loss : 24.716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.553 | G Loss : 24.710\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.553 | G Loss : 24.703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.553 | G Loss : 24.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.553 | G Loss : 24.691\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.553 | G Loss : 24.689\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.553 | G Loss : 24.686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000012.png and g_model & d_model\n",
      " ========== Epoch 13 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.553 | G Loss : 24.678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.553 | G Loss : 24.670\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.553 | G Loss : 24.663\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.553 | G Loss : 24.656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.553 | G Loss : 24.649\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.553 | G Loss : 24.643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.553 | G Loss : 24.636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.553 | G Loss : 24.629\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.553 | G Loss : 24.622\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.553 | G Loss : 24.616\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.553 | G Loss : 24.609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.553 | G Loss : 24.601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.553 | G Loss : 24.595\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.553 | G Loss : 24.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.553 | G Loss : 24.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.553 | G Loss : 24.581\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.553 | G Loss : 24.577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.553 | G Loss : 24.571\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.553 | G Loss : 24.565\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.553 | G Loss : 24.559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "Batch : 21, D Loss : 3.553 | G Loss : 24.552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 22, D Loss : 3.553 | G Loss : 24.546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 23, D Loss : 3.553 | G Loss : 24.541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.553 | G Loss : 24.536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.553 | G Loss : 24.529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.553 | G Loss : 24.525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 24.522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 24.517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 24.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 24.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 24.506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 24.500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 24.496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 24.492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 24.486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 24.480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 24.473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 24.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 24.462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 24.456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 24.449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 24.442\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 24.435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 24.429\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 24.423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 24.416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000013.png and g_model & d_model\n",
      " ========== Epoch 14 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 24.409\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 24.402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 24.397\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 24.391\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 24.385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 24.381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 24.376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 24.372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 24.366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 24.365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 24.364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 24.361\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 24.356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 24.352\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 24.348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.553 | G Loss : 24.343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.553 | G Loss : 24.337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.553 | G Loss : 24.333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 24.328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 24.326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 24.324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 24.320\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 24.314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 24.309\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 24.305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 24.299\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 24.293\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 24.290\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 24.284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 24.281\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 24.276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 24.273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 24.270\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 24.266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 24.261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 24.257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 24.253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 24.249\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 24.244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 24.240\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 24.234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 24.230\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 24.226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 24.222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 24.218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 24.213\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000014.png and g_model & d_model\n",
      " ========== Epoch 15 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 24.207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 24.201\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 24.195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 24.190\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 24.188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 24.188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 24.187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 24.184\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 24.181\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 24.178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 24.173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 24.168\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 24.163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 24.158\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 24.153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 24.149\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 24.144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 24.138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 24.136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 24.135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 24.130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 24.126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 24.122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 24.118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 24.113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 24.107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 24.102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 24.102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 24.100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 24.097\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 24.094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 24.089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 24.083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 24.078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 24.073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 24.067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 24.062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 24.058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 24.054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 24.050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 24.045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 24.040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 24.035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 24.031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 24.034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 24.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000015.png and g_model & d_model\n",
      " ========== Epoch 16 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 24.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 24.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 24.017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 24.012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 24.008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 24.004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 23.999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 23.994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 23.989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 23.985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 23.980\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 23.974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 23.969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 23.963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 23.957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 23.952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 23.946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 23.940\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 23.936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 23.933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 23.929\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 23.923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 23.918\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 23.914\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 23.911\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 23.906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 23.901\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 23.895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 23.891\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 23.887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 23.883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 23.879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 23.876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 23.873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 23.868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 23.864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 23.860\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 23.854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 23.849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 23.845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 23.840\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 23.839\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 23.834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 23.830\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 23.824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 23.820\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000016.png and g_model & d_model\n",
      " ========== Epoch 17 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 23.818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 23.816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 23.813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 23.809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 23.804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 23.799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 23.795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 23.791\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 23.786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 23.781\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 23.776\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 23.772\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 23.767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 23.764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 23.760\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 23.755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 23.751\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 23.747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 23.743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 23.738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 23.733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 23.729\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 23.725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 23.722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 23.718\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 23.713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 23.708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 23.704\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 23.699\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 23.694\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 23.690\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 23.685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 23.680\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 23.676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 23.673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 23.671\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 23.669\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 23.664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 23.661\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 23.657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 23.653\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 23.648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 23.648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 23.646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 23.642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 23.638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000017.png and g_model & d_model\n",
      " ========== Epoch 18 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 23.634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 23.629\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 23.624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 23.620\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 23.616\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 23.612\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 23.610\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 23.607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 23.604\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 23.599\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 23.597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 23.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 23.590\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 23.589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 23.588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 23.587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 23.583\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 23.579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 23.574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 23.571\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 23.569\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 23.568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 23.564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 23.560\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 23.556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 23.553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 23.550\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 23.547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 23.542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 23.538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 23.533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 23.530\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 23.527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 23.523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 23.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 23.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 23.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 23.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 23.504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 23.499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 23.495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 23.491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 23.488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 23.486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 23.481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 23.477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000018.png and g_model & d_model\n",
      " ========== Epoch 19 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 23.474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 23.473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 23.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 23.468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 23.466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 23.463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 23.458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 23.455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 23.452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 23.447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 23.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 23.441\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 23.438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 23.435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 23.432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 23.428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 23.425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 23.420\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 23.416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 23.412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 23.408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 23.403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 23.399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 23.395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 23.391\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 23.386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 23.382\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 23.379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 23.376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 23.374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 23.370\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 23.365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 23.362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 23.359\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 23.356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 23.351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 23.349\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 23.347\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 23.344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 23.340\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 23.336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 23.333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 23.331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 23.328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 23.325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 23.321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000019.png and g_model & d_model\n",
      " ========== Epoch 20 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 23.318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 23.314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 23.310\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 23.306\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 23.305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 23.303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 23.300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 23.297\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 23.294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 23.291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 23.287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 23.284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 23.280\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 23.277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 23.274\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 23.271\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 23.268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 23.264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 23.260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 23.256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 23.253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 23.248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 23.244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 23.241\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 23.239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 23.236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 23.236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 23.235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 23.232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 23.230\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 23.227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 23.224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 23.221\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 23.219\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 23.215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 23.211\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 23.207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 23.205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 23.202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 23.199\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 23.197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 23.196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 23.193\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 23.190\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 23.187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 23.185\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000020.png and g_model & d_model\n",
      " ========== Epoch 21 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 23.182\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 23.179\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 23.176\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 23.172\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 23.169\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 23.165\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 23.163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 23.160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 23.157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 23.154\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 23.150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 23.147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 23.143\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 23.140\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 23.136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 23.132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 23.129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 23.126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 23.123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 23.118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 23.114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 23.111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 23.107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 23.104\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 23.101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 23.101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 23.103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 23.102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 23.101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 23.099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 23.096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 23.093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 23.091\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 23.087\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 23.083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 23.080\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 23.077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 23.073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 23.069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 23.066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 23.063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 23.060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 23.057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 23.053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 23.049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 23.045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000021.png and g_model & d_model\n",
      " ========== Epoch 22 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 23.042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 23.039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 23.036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 23.033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 23.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 23.027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 23.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 23.020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 23.016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 23.012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 23.008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 23.004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 23.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 22.997\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 22.993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 22.990\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 22.989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 22.986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 22.985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 22.982\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 22.978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 22.975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 22.972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 22.969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 22.965\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 22.962\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 22.959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 22.959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 22.956\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 22.953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 22.950\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 22.946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 22.944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 22.941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 22.938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 22.935\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 22.931\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 22.928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 22.925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 22.922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 22.920\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 22.917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 22.914\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 22.910\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 22.908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 22.904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000022.png and g_model & d_model\n",
      " ========== Epoch 23 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 22.901\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 22.898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 22.895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 22.891\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 22.889\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 22.885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 22.883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 22.880\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 22.877\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 22.873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 22.869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 22.866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 22.867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 22.867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 22.866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 22.864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 22.863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 22.861\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 22.858\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 22.856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 22.854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 22.852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 22.853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 22.853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 22.852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 22.850\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 22.849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 22.847\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 22.846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 22.844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 22.844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 22.843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 22.842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 22.842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 22.841\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 22.838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 22.837\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 22.835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 22.833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 22.830\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 22.828\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 22.826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 22.826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 22.827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 22.829\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 22.828\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000023.png and g_model & d_model\n",
      " ========== Epoch 24 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 22.827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 22.825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 22.823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 22.822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 22.820\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 22.818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 22.816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 22.814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 22.811\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 22.808\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 22.805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 22.801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 22.799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 22.796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 22.794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 22.791\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 22.788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 22.785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 22.783\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 22.780\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 22.778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 22.778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 22.777\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 22.775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 22.774\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 22.771\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 22.768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 22.765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 22.762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 22.760\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 22.757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 22.754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 22.752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 22.751\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 22.748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 22.745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 22.743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 22.740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 22.737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 22.735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 22.732\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 22.730\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 22.728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 22.726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 22.726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 22.723\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000024.png and g_model & d_model\n",
      " ========== Epoch 25 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 22.720\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 22.718\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 22.716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 22.713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 22.711\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 22.708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 22.706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 22.704\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 22.701\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 22.698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 22.696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 22.693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 22.691\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 22.688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 22.685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 22.682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 22.684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 22.685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 22.684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 22.685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 22.682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 22.680\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 22.678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 22.675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 22.673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 22.670\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 22.667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 22.665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 22.662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 22.660\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 22.658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 22.656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 22.653\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 22.651\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 22.649\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 22.647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 22.645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 22.643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 22.639\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 22.637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 22.634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 22.632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 22.630\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 22.629\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 22.626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 22.623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000025.png and g_model & d_model\n",
      " ========== Epoch 26 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 22.621\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 22.619\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 22.618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 22.615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 22.612\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 22.609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 22.607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 22.605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 22.603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 22.602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 22.602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 22.601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 22.599\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 22.596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 22.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 22.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 22.589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 22.586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 22.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 22.582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 22.579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 22.576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 22.575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 22.572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 22.570\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 22.568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 22.566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 22.564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 22.561\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 22.560\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 22.558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 22.555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 22.553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 22.551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 22.548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 22.546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 22.544\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 22.542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 22.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 22.536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 22.534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 22.532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 22.529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 22.526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 22.524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 22.522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000026.png and g_model & d_model\n",
      " ========== Epoch 27 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 22.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 22.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 22.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 22.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 22.513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 22.513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 22.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 22.513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 22.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 22.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 22.506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 22.503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 22.500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 22.498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 22.495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 22.492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 22.490\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 22.487\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 22.484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 22.482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 22.480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 22.478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 22.476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 22.473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 22.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 22.468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 22.466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 22.465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 22.464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 22.463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 22.460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 22.459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 22.457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 22.455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 22.453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 22.451\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 22.449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 22.447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 22.446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 22.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 22.442\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 22.440\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 22.437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 22.435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 22.432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 22.429\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000027.png and g_model & d_model\n",
      " ========== Epoch 28 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 22.427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 22.424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 22.421\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 22.420\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 22.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 22.415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 22.413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 22.411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 22.408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 22.406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 22.403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 22.400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 22.398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 22.395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 22.393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 22.391\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 22.390\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 22.388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 22.386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 22.383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 22.382\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 22.379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 22.377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 22.375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 22.374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 22.372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 22.369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 22.367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 22.365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 22.364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 22.364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 22.363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 22.361\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 22.359\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 22.358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 22.356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 22.354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 22.351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 22.349\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 22.346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 22.343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 22.341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 22.338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 22.336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 22.333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 22.330\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000028.png and g_model & d_model\n",
      " ========== Epoch 29 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 22.328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 22.326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 22.324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 22.321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 22.319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 22.318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 22.315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 22.313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 22.312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 22.311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 22.309\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 22.307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 22.305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 22.303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 22.301\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 22.299\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 22.297\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 22.295\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 22.293\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 22.291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 22.290\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 22.288\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 22.287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 22.287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 22.285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 22.283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 22.282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 22.279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 22.278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 22.276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 22.274\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 22.272\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 22.270\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 22.268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 22.266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 22.264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 22.262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 22.260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 22.258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 22.256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 22.255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 22.253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 22.251\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 22.249\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 22.246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 22.244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000029.png and g_model & d_model\n",
      " ========== Epoch 30 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 22.242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 22.240\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 22.239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 22.237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 22.235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 22.233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 22.232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 22.232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 22.233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 22.232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 22.231\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 22.229\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 22.227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 22.226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 22.224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 22.222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 22.220\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 22.221\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 22.220\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 22.221\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 22.223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 22.224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 22.224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 22.224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 22.223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 22.222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 22.222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 22.220\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 22.218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 22.217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 22.216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 22.214\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 22.213\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 22.211\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 22.211\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 22.209\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 22.207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 22.205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 22.204\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 22.202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 22.201\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 22.200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 22.198\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 22.196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 22.195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 22.196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000030.png and g_model & d_model\n",
      " ========== Epoch 31 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 22.194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 22.192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 22.191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 22.189\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 22.188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 22.187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 22.186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 22.186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 22.186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 22.184\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 22.183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 22.181\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 22.179\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 22.177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 22.175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 22.173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 22.171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 22.169\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 22.167\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 22.165\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 22.163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 22.162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 22.160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 22.158\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 22.156\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 22.154\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 22.152\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 22.150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 22.147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 22.145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 22.144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 22.142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 22.140\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 22.138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 22.137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 22.135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 22.133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 22.132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 22.130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 22.128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 22.126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 22.124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 22.123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 22.121\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 22.120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 22.119\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000031.png and g_model & d_model\n",
      " ========== Epoch 32 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 22.118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 22.117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 22.114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 22.113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 22.111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 22.109\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 22.107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 22.105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 22.105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 22.103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 22.101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 22.100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 22.098\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 22.095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 22.093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 22.091\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 22.089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 22.087\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 22.084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 22.082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 22.080\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 22.077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 22.076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 22.074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 22.073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 22.072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 22.069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 22.068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 22.066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 22.064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 22.063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 22.062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 22.061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 22.059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 22.058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 22.056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 22.054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 22.052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 22.050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 22.049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 22.047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 22.046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 22.044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 22.043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 22.041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 22.039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000032.png and g_model & d_model\n",
      " ========== Epoch 33 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 22.037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 22.035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 22.034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 22.032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 22.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 22.028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 22.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 22.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 22.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 22.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 22.020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 22.018\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 22.018\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 22.015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 22.013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 22.012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 22.010\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 22.009\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 22.006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 22.004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 22.003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 22.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.997\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.990\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.981\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.979\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.971\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.965\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000033.png and g_model & d_model\n",
      " ========== Epoch 34 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.965\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.962\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.960\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.955\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.950\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.949\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.949\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.947\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.940\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.934\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.931\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.930\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.930\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.920\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.918\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.915\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.914\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.913\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.910\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.909\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.901\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000034.png and g_model & d_model\n",
      " ========== Epoch 35 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.900\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.899\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.892\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.891\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.890\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.890\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.890\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.889\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.877\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.874\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.872\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.870\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.862\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.861\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.860\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.859\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.858\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.857\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.857\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.851\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.851\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.850\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000035.png and g_model & d_model\n",
      " ========== Epoch 36 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.840\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.839\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.837\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.830\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.829\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.821\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.819\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.812\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.810\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.808\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.800\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.790\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.783\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.780\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.777\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000036.png and g_model & d_model\n",
      " ========== Epoch 37 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.774\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.773\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.771\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.770\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.770\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.769\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.760\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.759\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.758\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.758\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.760\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.760\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.759\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.751\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.749\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 21.747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 21.746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.739\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000037.png and g_model & d_model\n",
      " ========== Epoch 38 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.732\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.731\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.729\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.721\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.719\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.718\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.711\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 21.709\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 21.707\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 21.706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.704\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.701\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.699\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.695\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.692\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.691\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.690\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.689\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.679\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.677\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000038.png and g_model & d_model\n",
      " ========== Epoch 39 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.670\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.669\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.668\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.666\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 21.662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 21.660\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.659\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 21.655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 21.653\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 21.652\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 21.650\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 21.648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 21.647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 21.645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 21.643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 21.639\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 21.633\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 21.633\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 21.632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 21.631\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 21.629\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 21.628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 21.628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 21.626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 21.625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 21.624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 21.622\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.621\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.619\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 21.617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 21.616\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 21.614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000039.png and g_model & d_model\n",
      " ========== Epoch 40 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 21.613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 21.611\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 21.608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 21.607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 21.605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 21.603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 21.602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 21.600\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 21.599\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 21.598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 21.597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 21.595\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 21.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 21.592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 21.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 21.590\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 21.589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 21.587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 21.586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 21.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 21.583\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 21.582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 21.580\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 21.578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 21.577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 21.575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 21.573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 21.572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 21.571\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 21.570\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 21.569\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 21.567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 21.566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 21.564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 21.562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 21.561\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 21.560\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 21.559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 21.558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 21.557\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 21.555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 21.554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 21.553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 21.552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 21.550\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000040.png and g_model & d_model\n",
      " ========== Epoch 41 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 21.549\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 21.547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 21.546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 21.545\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 21.543\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.540\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 21.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 21.538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 21.537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 21.535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 21.534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 21.534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 21.534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 21.534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 21.533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 21.532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 21.531\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 21.530\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 21.528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 21.527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 21.526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 21.524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 21.523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 21.521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 21.521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 21.521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 21.520\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 21.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 21.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 21.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 21.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 21.517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 21.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 21.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 21.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 21.513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 21.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 21.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 21.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 21.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000041.png and g_model & d_model\n",
      " ========== Epoch 42 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 21.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 21.505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 21.499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 21.498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 21.497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 21.495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 21.494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 21.493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 21.492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 21.491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 21.489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 21.489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 21.499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 21.502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 21.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 21.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 21.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000042.png and g_model & d_model\n",
      " ========== Epoch 43 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.490\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000043.png and g_model & d_model\n",
      " ========== Epoch 44 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.490\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.487\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000044.png and g_model & d_model\n",
      " ========== Epoch 45 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.479\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.471\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.461\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.451\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.450\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000045.png and g_model & d_model\n",
      " ========== Epoch 46 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.442\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.441\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.440\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.431\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.430\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.429\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.426\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.421\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.420\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.419\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.410\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.409\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.401\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000046.png and g_model & d_model\n",
      " ========== Epoch 47 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.392\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.391\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.390\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.382\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.380\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.371\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.370\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.361\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.361\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.361\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.359\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000047.png and g_model & d_model\n",
      " ========== Epoch 48 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.355\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.355\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.352\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.349\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.347\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.340\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.339\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.330\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.329\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000048.png and g_model & d_model\n",
      " ========== Epoch 49 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.322\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.320\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.310\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.309\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.306\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.304\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.304\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.301\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.299\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.298\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.297\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.296\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.295\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.293\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.293\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.290\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.289\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.288\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000049.png and g_model & d_model\n",
      " ========== Epoch 50 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.281\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.280\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.274\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.272\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.271\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.270\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.269\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.259\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.251\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.249\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.240\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000050.png and g_model & d_model\n",
      " ========== Epoch 51 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.231\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.230\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.229\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.229\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.225\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.221\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.220\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.219\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.214\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.213\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.212\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.211\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.210\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.209\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.206\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.204\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.203\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.201\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.201\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.199\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.199\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000051.png and g_model & d_model\n",
      " ========== Epoch 52 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.198\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.193\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.190\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.189\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.189\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.185\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.184\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.184\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.181\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.181\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.180\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.179\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.176\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.176\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.172\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.170\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.169\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.168\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.169\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.168\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.168\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.167\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.165\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.165\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.164\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000052.png and g_model & d_model\n",
      " ========== Epoch 53 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.161\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.159\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.158\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.156\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.154\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.152\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.151\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.149\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.148\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.143\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.141\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.140\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.139\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.134\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.131\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.127\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.127\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000053.png and g_model & d_model\n",
      " ========== Epoch 54 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.121\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.119\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.119\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.119\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.116\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.110\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.109\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.109\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.106\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.098\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.091\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.090\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.087\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.086\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000054.png and g_model & d_model\n",
      " ========== Epoch 55 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.080\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.079\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.071\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.070\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.070\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000055.png and g_model & d_model\n",
      " ========== Epoch 56 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 21.031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 21.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 21.029\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 21.029\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 21.028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 21.027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 21.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 21.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 21.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 21.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 21.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000056.png and g_model & d_model\n",
      " ========== Epoch 57 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 21.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 21.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 21.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 21.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 21.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 21.020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 21.019\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 21.018\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 21.017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 21.016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 21.016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 21.015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 21.016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 21.016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 21.015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 21.015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 21.014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 21.013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 21.012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 21.012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 21.011\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 21.010\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 21.010\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 21.009\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 21.009\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 21.008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 21.007\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 21.006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 21.006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 21.005\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 21.004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 21.003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 21.002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 21.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 21.000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.998\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.997\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000057.png and g_model & d_model\n",
      " ========== Epoch 58 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.991\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.991\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.990\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.987\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.982\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.981\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.980\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.980\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.970\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.970\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.965\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.962\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.961\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.961\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.960\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.956\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.955\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.954\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.954\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.950\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000058.png and g_model & d_model\n",
      " ========== Epoch 59 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.950\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.947\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.940\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.939\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.935\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.934\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.934\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.931\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.931\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.930\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.929\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.929\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.920\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.919\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.918\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.915\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.914\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.913\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.911\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.910\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000059.png and g_model & d_model\n",
      " ========== Epoch 60 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.910\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.909\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.902\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.901\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.901\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.900\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.899\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.897\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.893\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.892\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.891\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.890\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.889\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.880\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.877\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.874\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.872\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.871\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000060.png and g_model & d_model\n",
      " ========== Epoch 61 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.870\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.862\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.861\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.860\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.859\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.858\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.857\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.851\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.850\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.850\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.847\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.841\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.840\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.840\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.839\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.837\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000061.png and g_model & d_model\n",
      " ========== Epoch 62 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.831\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.830\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.829\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.828\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.821\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.821\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.820\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.819\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.812\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.812\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.811\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000062.png and g_model & d_model\n",
      " ========== Epoch 63 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.811\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.810\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.810\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.810\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.808\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.800\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.800\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.791\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.791\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.790\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.789\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.789\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.789\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000063.png and g_model & d_model\n",
      " ========== Epoch 64 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.783\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.783\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.781\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.781\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.780\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.777\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.776\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.776\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.774\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.774\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.773\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.772\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.772\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.771\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.771\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.770\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.770\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.769\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.769\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.769\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000064.png and g_model & d_model\n",
      " ========== Epoch 65 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.760\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.759\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.758\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.758\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.751\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.750\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.749\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.749\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.741\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.741\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.741\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.739\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.739\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.732\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000065.png and g_model & d_model\n",
      " ========== Epoch 66 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.731\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.730\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.729\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.729\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.729\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.723\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.723\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.721\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.721\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.720\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.719\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.719\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.718\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.712\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.711\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.710\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.710\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.710\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.709\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.707\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.707\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.704\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.704\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000066.png and g_model & d_model\n",
      " ========== Epoch 67 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.701\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.700\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.699\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.695\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.694\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.692\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.691\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.691\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.690\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.690\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.689\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.683\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.680\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.680\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.679\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.680\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.680\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.680\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.679\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.679\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.677\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.677\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.674\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000067.png and g_model & d_model\n",
      " ========== Epoch 68 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.671\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.670\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.669\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.668\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.668\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.666\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.663\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.663\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.661\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.661\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.660\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.659\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.659\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.653\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.652\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.652\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.651\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.650\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.650\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.649\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000068.png and g_model & d_model\n",
      " ========== Epoch 69 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.640\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.639\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.633\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.633\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.631\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.630\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.630\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.629\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.622\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.621\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.620\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.620\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.619\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.616\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.612\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.611\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.610\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.610\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000069.png and g_model & d_model\n",
      " ========== Epoch 70 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.606\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.606\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.604\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.600\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.600\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.599\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.599\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.595\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.590\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000070.png and g_model & d_model\n",
      " ========== Epoch 71 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.590\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.590\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.590\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.590\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.590\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000071.png and g_model & d_model\n",
      " ========== Epoch 72 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.583\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.583\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.581\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.581\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.580\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.580\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 20.572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 20.572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 20.572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.571\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.570\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.570\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 20.569\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 20.569\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.569\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000072.png and g_model & d_model\n",
      " ========== Epoch 73 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.565\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.565\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.563\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.563\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.561\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.560\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.560\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.557\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.550\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.550\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.550\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.550\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.550\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.549\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.549\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000073.png and g_model & d_model\n",
      " ========== Epoch 74 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.545\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.544\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.544\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.543\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.540\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.540\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.540\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.531\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.531\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.530\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.530\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000074.png and g_model & d_model\n",
      " ========== Epoch 75 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.520\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 20.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 20.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 20.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 20.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 20.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 20.517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 20.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 20.515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 20.515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 20.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 20.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 20.513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 20.513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 20.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 20.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 20.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 20.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 20.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 20.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 20.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 20.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 20.506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 20.505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 20.505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 20.504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000075.png and g_model & d_model\n",
      " ========== Epoch 76 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 20.504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 20.504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 20.503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 20.503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 20.491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 20.490\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 20.490\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 20.489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 20.489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 20.488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.487\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 20.483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 20.482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 20.482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000076.png and g_model & d_model\n",
      " ========== Epoch 77 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.479\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 20.479\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 20.474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 20.473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 20.473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 20.473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 20.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 20.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 20.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 20.471\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 20.471\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 20.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 20.469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 20.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 20.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 20.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 20.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 20.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 20.469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 20.469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 20.468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 20.468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 20.468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 20.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 20.466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 20.466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 20.465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000077.png and g_model & d_model\n",
      " ========== Epoch 78 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 20.465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 20.465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 20.464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 20.464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 20.464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 20.463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 20.463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 20.462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 20.462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 20.461\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 20.461\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 20.460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 20.460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 20.460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 20.459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 20.459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 20.458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 20.458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 20.458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 20.457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 20.457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 20.456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 20.456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 20.455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 20.455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 20.454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 20.453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 20.453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 20.453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 20.452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 20.452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 20.452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.451\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.451\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.450\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 20.450\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 20.449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 20.448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 20.447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 20.447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 20.446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 20.445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 20.445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 20.445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000078.png and g_model & d_model\n",
      " ========== Epoch 79 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 20.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 20.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 20.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 20.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 20.443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 20.442\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 20.442\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 20.441\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 20.441\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 20.441\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 20.441\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 20.441\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 20.440\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 20.440\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 20.439\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 20.439\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 20.438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 20.438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 20.437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 20.437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 20.437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 20.436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 20.435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 20.435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 20.434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 20.434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 20.433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 20.433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 20.433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 20.433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 20.432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 20.432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.431\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.431\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.430\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 20.430\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 20.429\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.429\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 20.428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 20.427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 20.427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.426\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 20.426\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 20.425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 20.425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 20.424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000079.png and g_model & d_model\n",
      " ========== Epoch 80 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 20.424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 20.423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 20.422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 20.422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 20.421\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 20.420\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 20.420\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 20.419\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 20.419\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 20.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 20.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 20.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 20.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 20.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 20.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 20.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 20.416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 20.416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 20.415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 20.415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 20.415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 20.415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 20.415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 20.414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 20.414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 20.414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 20.413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 20.413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 20.412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 20.412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 20.411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 20.411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.410\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.410\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.410\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 20.409\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 20.409\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 20.407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 20.407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 20.406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 20.405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 20.404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 20.405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 20.405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000080.png and g_model & d_model\n",
      " ========== Epoch 81 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 20.405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 20.404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 20.404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 20.403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 20.403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 20.403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 20.402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 20.402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 20.402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 20.401\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 20.400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 20.400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 20.399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 20.399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 20.398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 20.398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 20.397\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 20.397\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 20.396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 20.395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 20.395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 20.394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 20.394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 20.393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 20.393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 20.392\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 20.391\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 20.391\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 20.390\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 20.390\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 20.389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 20.389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 20.387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 20.387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 20.386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 20.385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 20.385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 20.384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 20.383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 20.382\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 20.382\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000081.png and g_model & d_model\n",
      " ========== Epoch 82 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 20.381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 20.381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 20.380\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 20.379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 20.379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 20.378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 20.378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 20.378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 20.377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 20.377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 20.376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 20.376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 20.375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 20.375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 20.374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 20.373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 20.373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 20.372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 20.371\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 20.371\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 20.370\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 20.369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 20.369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 20.368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 20.368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 20.367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 20.366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 20.366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 20.365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 20.364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 20.364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 20.363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.361\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 20.360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 20.360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 20.360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 20.360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 20.360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.359\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 20.359\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 20.358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 20.357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 20.357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000082.png and g_model & d_model\n",
      " ========== Epoch 83 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.355\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.355\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 20.354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 20.353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 20.353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.352\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.352\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.349\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.347\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.340\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.339\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.339\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 20.338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 20.336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 20.335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 20.334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 20.334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 20.333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 20.332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 20.332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 20.332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 20.332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000083.png and g_model & d_model\n",
      " ========== Epoch 84 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 20.331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 20.331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 20.330\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 20.329\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 20.329\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 20.328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 20.328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 20.327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 20.327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 20.326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 20.325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 20.325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 20.325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 20.325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 20.324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 20.324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 20.323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 20.323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 20.323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 20.322\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 20.321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 20.321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 20.320\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 20.320\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 20.319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 20.319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 20.318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 20.318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 20.317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 20.317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 20.316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 20.316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 20.314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 20.314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 20.313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 20.312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 20.312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 20.311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 20.311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 20.310\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 20.310\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000084.png and g_model & d_model\n",
      " ========== Epoch 85 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 20.309\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 20.309\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 20.308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 20.308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 20.307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 20.306\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 20.306\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.304\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 20.304\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 20.304\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 20.303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 20.303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 20.302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 20.302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 20.301\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 20.301\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.301\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 20.300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 20.300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 20.300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 20.299\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 20.299\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.299\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.298\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.298\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.297\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.297\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.296\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.296\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.295\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.295\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.293\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.293\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.290\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.290\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.289\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.288\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000085.png and g_model & d_model\n",
      " ========== Epoch 86 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.288\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.281\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.281\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.280\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.280\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.274\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.272\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.272\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.271\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.271\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.271\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.271\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.271\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.271\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.270\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.270\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.269\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.269\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.269\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.554 | G Loss : 20.266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 20.266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 20.266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000086.png and g_model & d_model\n",
      " ========== Epoch 87 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 20.265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 20.265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 20.265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 20.266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.554 | G Loss : 20.267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 20.267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 20.267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 20.267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 20.267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.554 | G Loss : 20.267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 11, D Loss : 3.554 | G Loss : 20.267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 20.266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 20.266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 20.266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 20.265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 20.265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 20.264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 20.263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 20.263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 20.263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 20.263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 20.263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 20.262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 20.262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 20.261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 20.261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.554 | G Loss : 20.260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 20.260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 20.259\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 20.260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 20.260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 20.261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 20.260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 20.260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.260\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 20.259\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.554 | G Loss : 20.259\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 20.259\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 20.258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.554 | G Loss : 20.257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.554 | G Loss : 20.256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000087.png and g_model & d_model\n",
      " ========== Epoch 88 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.554 | G Loss : 20.256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.554 | G Loss : 20.255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 20.255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.554 | G Loss : 20.254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.554 | G Loss : 20.253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.554 | G Loss : 20.253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.554 | G Loss : 20.252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.251\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 20.251\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.554 | G Loss : 20.251\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.554 | G Loss : 20.251\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.554 | G Loss : 20.250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.554 | G Loss : 20.250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.554 | G Loss : 20.249\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.554 | G Loss : 20.249\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.554 | G Loss : 20.248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.554 | G Loss : 20.248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.554 | G Loss : 20.247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.554 | G Loss : 20.247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.554 | G Loss : 20.247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.554 | G Loss : 20.246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.554 | G Loss : 20.246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.554 | G Loss : 20.245\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.245\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.554 | G Loss : 20.244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.554 | G Loss : 20.243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.554 | G Loss : 20.243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.554 | G Loss : 20.243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.554 | G Loss : 20.242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.554 | G Loss : 20.242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.241\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.241\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.554 | G Loss : 20.240\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.554 | G Loss : 20.240\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.554 | G Loss : 20.239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 20.238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000088.png and g_model & d_model\n",
      " ========== Epoch 89 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.231\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.231\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.230\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.230\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.229\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.229\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.228\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.228\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.554 | G Loss : 20.226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.554 | G Loss : 20.226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.225\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.225\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.554 | G Loss : 20.225\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.225\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.225\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.554 | G Loss : 20.224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.554 | G Loss : 20.224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.554 | G Loss : 20.224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000089.png and g_model & d_model\n",
      " ========== Epoch 90 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.554 | G Loss : 20.221\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.554 | G Loss : 20.221\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.220\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.220\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.219\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.219\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.554 | G Loss : 20.217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.214\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.214\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.214\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.213\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.212\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.212\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.211\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.211\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.210\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.210\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.209\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.206\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.206\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.204\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.203\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.203\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.201\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.199\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000090.png and g_model & d_model\n",
      " ========== Epoch 91 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.199\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.198\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.198\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.193\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.193\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.190\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.190\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.189\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.189\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.185\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.185\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.184\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.184\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.182\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.182\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.181\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000091.png and g_model & d_model\n",
      " ========== Epoch 92 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.181\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.180\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.179\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.179\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.179\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.176\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.176\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.172\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.172\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.170\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.170\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.169\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.169\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.168\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.168\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.167\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.167\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.167\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.165\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.165\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.164\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.164\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000092.png and g_model & d_model\n",
      " ========== Epoch 93 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.161\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.161\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.159\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.159\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.158\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.158\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.156\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.156\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.154\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.154\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.152\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.152\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.151\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.151\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.151\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.149\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.149\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.149\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.148\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.143\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.141\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000093.png and g_model & d_model\n",
      " ========== Epoch 94 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.141\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.140\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.140\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.140\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.139\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.139\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.139\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.134\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.134\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.131\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.131\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.127\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.127\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000094.png and g_model & d_model\n",
      " ========== Epoch 95 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.121\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.121\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.119\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.119\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.116\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.116\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.116\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.110\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.110\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.110\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.110\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.110\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.109\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.109\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.109\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000095.png and g_model & d_model\n",
      " ========== Epoch 96 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.106\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.106\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.104\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.104\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.104\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.098\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.098\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.097\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.097\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.091\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.091\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.091\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.090\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.090\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000096.png and g_model & d_model\n",
      " ========== Epoch 97 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.087\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.087\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.086\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.080\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.080\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.079\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.079\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.071\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.071\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.071\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.070\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.070\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.070\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000097.png and g_model & d_model\n",
      " ========== Epoch 98 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000098.png and g_model & d_model\n",
      " ========== Epoch 99 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000099.png and g_model & d_model\n",
      " ========== Epoch 100 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.029\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.029\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000100.png and g_model & d_model\n",
      " ========== Epoch 101 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.019\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.019\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.018\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.018\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.018\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 20.016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 20.016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 20.015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 20.015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 20.015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 20.014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 20.014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 20.014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 20.013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 20.013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 20.012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 20.012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 20.012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 20.011\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 20.011\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 20.010\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 20.010\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 20.009\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 20.009\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 20.008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 20.008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 20.007\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 20.007\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 20.006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 20.006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 20.006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 20.005\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 20.004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 20.004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 20.004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 20.003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 20.003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 20.003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000101.png and g_model & d_model\n",
      " ========== Epoch 102 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 20.003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 20.003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 20.003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 20.002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 20.002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 20.002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 20.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 20.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 20.001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 20.000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 20.000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 20.000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 20.000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.998\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.998\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.997\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.997\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.997\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000102.png and g_model & d_model\n",
      " ========== Epoch 103 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.991\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.991\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.990\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.990\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.990\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.987\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.987\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.982\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.982\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.982\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.981\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.981\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.981\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.980\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.980\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.980\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.979\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.979\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000103.png and g_model & d_model\n",
      " ========== Epoch 104 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.971\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.971\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.971\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.970\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.970\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.970\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.965\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.965\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.965\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.962\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.962\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.962\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.961\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.961\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.961\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.960\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.960\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.960\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000104.png and g_model & d_model\n",
      " ========== Epoch 105 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.956\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.956\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.955\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.955\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.955\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.955\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.954\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.954\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.954\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.950\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.950\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.949\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.949\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.947\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.947\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000105.png and g_model & d_model\n",
      " ========== Epoch 106 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.940\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.940\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.939\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.939\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.935\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.935\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.935\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.934\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.934\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.931\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.931\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.931\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.931\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.930\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.930\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.930\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.929\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.929\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.929\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000106.png and g_model & d_model\n",
      " ========== Epoch 107 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.920\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.920\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.919\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.919\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.919\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.919\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.918\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.918\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.918\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.915\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.915\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.914\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.914\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.914\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.913\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.913\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.911\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.911\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.911\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.910\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.910\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000107.png and g_model & d_model\n",
      " ========== Epoch 108 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.909\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.909\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.902\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.902\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.902\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.901\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.901\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.901\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.901\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.900\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.900\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.899\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.899\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.897\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.897\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.897\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.893\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.893\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.893\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.892\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000108.png and g_model & d_model\n",
      " ========== Epoch 109 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.892\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.891\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.891\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.890\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.890\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.889\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.889\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.889\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.880\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.880\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.880\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.877\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.877\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.877\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000109.png and g_model & d_model\n",
      " ========== Epoch 110 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.874\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.874\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.872\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.872\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.872\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.872\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.871\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.871\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.871\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.870\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.870\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.862\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.862\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.861\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.861\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.861\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.860\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.860\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.859\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.859\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.859\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.858\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.858\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.857\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.857\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000110.png and g_model & d_model\n",
      " ========== Epoch 111 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.851\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.851\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.850\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.850\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.850\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.850\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.847\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.847\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.841\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.841\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.841\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.840\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.840\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.840\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.839\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000111.png and g_model & d_model\n",
      " ========== Epoch 112 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.839\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.837\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.837\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.837\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.831\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.831\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.831\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.830\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.830\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.830\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.829\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.829\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.829\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.828\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.828\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.828\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000112.png and g_model & d_model\n",
      " ========== Epoch 113 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.821\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.821\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.821\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.820\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.820\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.820\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.819\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.819\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.812\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.812\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.812\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.811\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.811\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.811\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.811\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.810\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.810\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.808\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000113.png and g_model & d_model\n",
      " ========== Epoch 114 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.808\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.808\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.800\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.800\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.800\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000114.png and g_model & d_model\n",
      " ========== Epoch 115 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.791\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.791\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.791\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.790\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.790\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.789\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.789\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.783\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.783\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.783\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.781\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.781\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.781\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.780\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.780\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.780\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.780\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.777\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.777\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.777\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.776\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.776\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000115.png and g_model & d_model\n",
      " ========== Epoch 116 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.774\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.774\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.773\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.773\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.772\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.772\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.772\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.771\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.771\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.770\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.770\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.769\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.769\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.769\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000116.png and g_model & d_model\n",
      " ========== Epoch 117 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.760\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.760\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.759\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.759\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.759\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.759\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.759\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.758\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.758\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.751\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.751\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.751\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.750\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.750\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.749\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.749\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.749\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000117.png and g_model & d_model\n",
      " ========== Epoch 118 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.741\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.741\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.741\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.739\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.739\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.739\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.732\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.732\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.732\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000118.png and g_model & d_model\n",
      " ========== Epoch 119 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.731\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.731\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.731\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.731\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.730\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.730\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.729\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.729\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.723\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.723\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.721\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.721\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.720\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.720\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.720\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.719\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.719\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.719\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.718\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.718\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.718\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000119.png and g_model & d_model\n",
      " ========== Epoch 120 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.712\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.712\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.712\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.711\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.711\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.711\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.710\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.710\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.710\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.709\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.709\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.709\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.707\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.707\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.704\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.704\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000120.png and g_model & d_model\n",
      " ========== Epoch 121 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.701\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.701\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.701\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.700\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.700\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.700\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.699\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.699\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.699\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.699\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.699\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.695\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.695\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.695\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.694\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.694\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.694\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000121.png and g_model & d_model\n",
      " ========== Epoch 122 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.692\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.692\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.691\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.691\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.691\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.691\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.690\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.690\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.690\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.689\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.689\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.689\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.683\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.683\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.683\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.683\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.680\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.680\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.680\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.679\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.679\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.679\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.679\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000122.png and g_model & d_model\n",
      " ========== Epoch 123 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.677\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.677\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.674\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.674\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.674\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.671\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.671\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.671\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.670\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.670\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.670\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.669\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.669\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.669\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.669\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.668\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.668\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.668\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.666\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.666\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.663\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000123.png and g_model & d_model\n",
      " ========== Epoch 124 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.663\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.661\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.661\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.661\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.660\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.660\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.659\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.659\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.659\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.659\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.659\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.653\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.653\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.653\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.652\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.652\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.652\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.651\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.651\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.651\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.651\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.650\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.650\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.650\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.650\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.649\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.649\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000124.png and g_model & d_model\n",
      " ========== Epoch 125 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.649\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.649\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.640\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.640\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.639\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.639\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.639\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.639\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000125.png and g_model & d_model\n",
      " ========== Epoch 126 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.633\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.633\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.631\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.631\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.631\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.630\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.630\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.630\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.629\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.629\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.629\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.622\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.622\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.621\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.621\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.621\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.620\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.620\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.620\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000126.png and g_model & d_model\n",
      " ========== Epoch 127 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.620\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.619\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.619\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.616\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.616\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.612\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.612\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.612\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.611\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.611\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.611\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.610\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.610\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.610\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.606\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.606\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.606\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.604\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000127.png and g_model & d_model\n",
      " ========== Epoch 128 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.604\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.600\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.600\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.600\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.599\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.599\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.599\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.595\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.595\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.595\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000128.png and g_model & d_model\n",
      " ========== Epoch 129 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.590\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.590\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.590\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.583\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.583\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.583\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.581\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.581\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.581\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.580\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.580\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.580\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000129.png and g_model & d_model\n",
      " ========== Epoch 130 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.571\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.571\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.571\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.570\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.570\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.570\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.570\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.569\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.569\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.569\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.565\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.565\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.565\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.565\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.563\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.563\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.561\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000130.png and g_model & d_model\n",
      " ========== Epoch 131 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.561\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.561\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.561\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.560\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.560\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.560\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.557\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.557\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.550\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.550\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.550\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.549\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.549\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.545\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000131.png and g_model & d_model\n",
      " ========== Epoch 132 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.545\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.545\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.544\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.544\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.544\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.543\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.543\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.543\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.543\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.543\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.540\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.540\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.540\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.540\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000132.png and g_model & d_model\n",
      " ========== Epoch 133 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.531\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.531\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.531\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.530\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.530\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.530\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.520\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.520\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.520\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000133.png and g_model & d_model\n",
      " ========== Epoch 134 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.510\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000134.png and g_model & d_model\n",
      " ========== Epoch 135 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.490\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.490\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.490\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000135.png and g_model & d_model\n",
      " ========== Epoch 136 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.487\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.487\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.487\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.487\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.479\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.479\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000136.png and g_model & d_model\n",
      " ========== Epoch 137 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.471\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.471\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.471\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000137.png and g_model & d_model\n",
      " ========== Epoch 138 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.461\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.461\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.461\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000138.png and g_model & d_model\n",
      " ========== Epoch 139 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.451\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.451\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.451\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.450\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.450\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.450\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.450\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.442\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.442\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.442\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.441\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.441\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.441\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.440\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.440\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000139.png and g_model & d_model\n",
      " ========== Epoch 140 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.439\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.439\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.439\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.431\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.431\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.431\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.430\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.430\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.430\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.430\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.429\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.429\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000140.png and g_model & d_model\n",
      " ========== Epoch 141 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.426\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.426\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.421\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.421\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.421\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.420\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.420\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.420\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.420\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.419\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.419\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.419\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000141.png and g_model & d_model\n",
      " ========== Epoch 142 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.410\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.410\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.410\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.410\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.410\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.410\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.409\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.409\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.409\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.409\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000142.png and g_model & d_model\n",
      " ========== Epoch 143 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.401\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.401\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.401\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.401\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.400\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.397\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.397\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.397\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.392\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.392\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.392\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.391\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000143.png and g_model & d_model\n",
      " ========== Epoch 144 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.391\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.391\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.390\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.390\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.390\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.382\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.382\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.382\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.382\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.380\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.380\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.380\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.380\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000144.png and g_model & d_model\n",
      " ========== Epoch 145 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.371\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.371\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.371\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.371\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.370\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.370\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000145.png and g_model & d_model\n",
      " ========== Epoch 146 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.361\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.361\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.361\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.361\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.359\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.359\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.359\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000146.png and g_model & d_model\n",
      " ========== Epoch 147 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.355\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.355\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.355\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.355\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.352\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.352\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.352\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.352\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.350\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.349\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.349\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.349\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.347\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.347\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.347\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.347\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000147.png and g_model & d_model\n",
      " ========== Epoch 148 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.340\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.340\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.340\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.339\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.339\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.339\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000148.png and g_model & d_model\n",
      " ========== Epoch 149 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.330\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.330\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.330\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.330\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.329\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.329\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.329\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.322\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.322\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.322\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.320\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.320\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000149.png and g_model & d_model\n",
      " ========== Epoch 150 ========== \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 1, D Loss : 3.555 | G Loss : 19.320\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 2, D Loss : 3.555 | G Loss : 19.319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 3, D Loss : 3.555 | G Loss : 19.319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 4, D Loss : 3.555 | G Loss : 19.319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 5, D Loss : 3.555 | G Loss : 19.318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 6, D Loss : 3.555 | G Loss : 19.318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 7, D Loss : 3.555 | G Loss : 19.318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 8, D Loss : 3.555 | G Loss : 19.318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 9, D Loss : 3.555 | G Loss : 19.317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 10, D Loss : 3.555 | G Loss : 19.317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 11, D Loss : 3.555 | G Loss : 19.317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 12, D Loss : 3.555 | G Loss : 19.316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 13, D Loss : 3.555 | G Loss : 19.316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 14, D Loss : 3.555 | G Loss : 19.316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 15, D Loss : 3.555 | G Loss : 19.315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 16, D Loss : 3.555 | G Loss : 19.315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 17, D Loss : 3.555 | G Loss : 19.315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 18, D Loss : 3.555 | G Loss : 19.314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 19, D Loss : 3.555 | G Loss : 19.314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 20, D Loss : 3.555 | G Loss : 19.314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 21, D Loss : 3.555 | G Loss : 19.314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 22, D Loss : 3.555 | G Loss : 19.313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 23, D Loss : 3.555 | G Loss : 19.313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 24, D Loss : 3.555 | G Loss : 19.313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 25, D Loss : 3.555 | G Loss : 19.313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 26, D Loss : 3.555 | G Loss : 19.313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 27, D Loss : 3.555 | G Loss : 19.312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 28, D Loss : 3.555 | G Loss : 19.312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 29, D Loss : 3.555 | G Loss : 19.312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 30, D Loss : 3.555 | G Loss : 19.312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 31, D Loss : 3.555 | G Loss : 19.311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 32, D Loss : 3.555 | G Loss : 19.311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 33, D Loss : 3.555 | G Loss : 19.311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 34, D Loss : 3.555 | G Loss : 19.311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 35, D Loss : 3.555 | G Loss : 19.310\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Batch : 36, D Loss : 3.555 | G Loss : 19.310\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 37, D Loss : 3.555 | G Loss : 19.310\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 38, D Loss : 3.555 | G Loss : 19.310\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 39, D Loss : 3.555 | G Loss : 19.310\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 40, D Loss : 3.555 | G Loss : 19.309\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 41, D Loss : 3.555 | G Loss : 19.309\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 42, D Loss : 3.555 | G Loss : 19.309\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 43, D Loss : 3.555 | G Loss : 19.309\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 44, D Loss : 3.555 | G Loss : 19.308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 45, D Loss : 3.555 | G Loss : 19.308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Batch : 46, D Loss : 3.555 | G Loss : 19.308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000150.png and g_model & d_model\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# from keras.layers import Input\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import Adam\n",
    "# import tensorflow.keras.backend as K\n",
    "\n",
    "# Your GAN function:\n",
    "def GAN(g_model, d_model, img_shape):\n",
    "    d_model.trainable = False\n",
    "    in_img = Input(shape=img_shape)\n",
    "    gen_out = g_model(in_img)\n",
    "    dis_out = d_model([in_img, gen_out])\n",
    "    model = Model(in_img, [dis_out, gen_out], name='GAN')\n",
    "    return model\n",
    "\n",
    "# --- Assume you have already built your g_model and d_model, and loaded weights into them ---\n",
    "# For example:\n",
    "# d_model.load_weights('Models/Pixel[02]_Context[08]/discriminator_.weight.h5')\n",
    "# g_model.load_weights('Models/Pixel[02]_Context[08]/g_model.h5')\n",
    "\n",
    "# Set the image shape (adjust if needed)\n",
    "img_shape = (256, 256, 3)\n",
    "\n",
    "# Rebuild the GAN model using your function:\n",
    "gan_model = GAN(g_model, d_model, img_shape)\n",
    "\n",
    "# Compile the GAN model. Use run_eagerly=True to help debug any loss output issues.\n",
    "opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "gan_model.compile(optimizer=opt, \n",
    "                  loss=['binary_crossentropy', pixel_loss],  # using your pixel_loss as second loss\n",
    "                  loss_weights=[1, 100],\n",
    "                  run_eagerly=True)\n",
    "\n",
    "# Now, resume training with your custom train() function:\n",
    "# Make sure blue_sketch and blue_photo are loaded properly (as numpy arrays or lists convertible to arrays)\n",
    "train(\n",
    "    d_model, \n",
    "    g_model, \n",
    "    gan_model, \n",
    "    [blue_sketch[:1500], blue_photo[:1500]],  # Note: your train() function expects [blue_photo, blue_sketch] ordering; adjust if necessary.\n",
    "    'Models/Pixel[02]_Context[08]/', \n",
    "    n_epochs=150, \n",
    "    n_batch=32 # Resume training from epoch 28 (since 27 epochs are complete)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "d_model.save('Models/Pixel[02]_Context[08]/d_model.h5')\n",
    "g_model.save('Models/Pixel[02]_Context[08]/g_model.h5')\n",
    "gan_model.save('Models/Pixel[02]_Context[08]/gan_model.h5')\n",
    "print(\"Models saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
